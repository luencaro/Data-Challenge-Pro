{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11131163,"sourceType":"datasetVersion","datasetId":6942282}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importacion De Librerias y Datos**","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T06:41:13.492225Z","iopub.execute_input":"2025-04-25T06:41:13.492539Z","iopub.status.idle":"2025-04-25T06:41:13.496324Z","shell.execute_reply.started":"2025-04-25T06:41:13.492510Z","shell.execute_reply":"2025-04-25T06:41:13.495550Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Analisis Exploratorio De Datos (EDA)**","metadata":{}},{"cell_type":"code","source":"# Definir los tipos de dato para el dataset de prestadores\ndtypes_prestadores = {\n    'Geogra_Municipio_Id': 'category',\n    'max_cantidad': 'float64'\n}\n\n# Seleccionar solo las columnas relevantes para df_prestadores\ncols_to_use_prestadores = ['Geogra_Municipio_Id', 'max_cantidad']\n\n# Leer el archivo CSV de df_prestadores\ndf_prestadores = pd.read_excel(\n    \"/kaggle/input/data-sura/2.Red Prestadores.xlsx\",\n    usecols=cols_to_use_prestadores,\n    dtype=dtypes_prestadores\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:33:42.813426Z","iopub.execute_input":"2025-04-25T04:33:42.813781Z","iopub.status.idle":"2025-04-25T04:33:56.837176Z","shell.execute_reply.started":"2025-04-25T04:33:42.813755Z","shell.execute_reply":"2025-04-25T04:33:56.836005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vista previa de cada dataset\ndf_salud = df.copy()\nprint(\"DF Salud:\")\ndisplay(df_salud.head())\nprint(\"dtypes:\")\nprint(df_salud.dtypes)\n\n\nprint(\"DF Prestadores:\")\ndisplay(df_prestadores.head())\nprint(\"dtypes:\")\nprint(df_prestadores.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:34:27.063690Z","iopub.execute_input":"2025-04-25T04:34:27.064233Z","iopub.status.idle":"2025-04-25T04:34:28.390515Z","shell.execute_reply.started":"2025-04-25T04:34:27.064205Z","shell.execute_reply":"2025-04-25T04:34:28.389571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Información general de los DataFrame\nprint(\"Información de df_salud:\")\ndf_salud.info()\n\nprint(\"Informacion de Prestadores\")\ndf_prestadores.info()\n\n# Estadísticas descriptivas (numéricas y algunas categóricas)\nprint(\"Estadísticas descriptivas de df_salud:\")\ndisplay(df_salud.describe(include='all'))\n\nprint(\"Estadísticas descriptivas de df_salud:\")\ndisplay(df_prestadores.describe(include='all'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:34:44.996806Z","iopub.execute_input":"2025-04-25T04:34:44.997118Z","iopub.status.idle":"2025-04-25T04:34:48.131315Z","shell.execute_reply.started":"2025-04-25T04:34:44.997094Z","shell.execute_reply":"2025-04-25T04:34:48.130292Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analisis de Valores Nulos Y Duplicados**","metadata":{}},{"cell_type":"code","source":"# Valores nulos\nprint(\"Valores nulos de datos de Salud\")\ndf_salud.isnull().sum()\nprint(\"Valores nulos de datos de Prestadores\")\ndf_prestadores.isnull().sum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:34:51.475429Z","iopub.execute_input":"2025-04-25T04:34:51.475776Z","iopub.status.idle":"2025-04-25T04:34:52.515190Z","shell.execute_reply.started":"2025-04-25T04:34:51.475746Z","shell.execute_reply":"2025-04-25T04:34:52.514373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Duplicados de datos de Salud\")\ndf_salud.duplicated()\nprint(\"DUplicados de datos de Prestadores\")\ndf_prestadores.duplicated()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:34:55.215686Z","iopub.execute_input":"2025-04-25T04:34:55.215993Z","iopub.status.idle":"2025-04-25T04:35:00.529276Z","shell.execute_reply.started":"2025-04-25T04:34:55.215970Z","shell.execute_reply":"2025-04-25T04:35:00.528253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Estadísticas de capacidad máxima\ndisplay(df_prestadores[\"max_cantidad\"].describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:35:04.217415Z","iopub.execute_input":"2025-04-25T04:35:04.217753Z","iopub.status.idle":"2025-04-25T04:35:04.238473Z","shell.execute_reply.started":"2025-04-25T04:35:04.217726Z","shell.execute_reply":"2025-04-25T04:35:04.237716Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Tipos de Atencion Medica mas Comunes**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Identifica las 10 etiquetas más comunes\ntop10 = df_salud[\"Concepto_Factura_Desc\"].value_counts().nlargest(10).index\n\n# Filtra el DataFrame para quedarte sólo con esas 10\ndf_top10 = df_salud[df_salud[\"Concepto_Factura_Desc\"].isin(top10)]\n\n# Grafica de barras\nplt.figure(figsize=(10, 6))\nsns.countplot(\n    data=df_top10,\n    y=\"Concepto_Factura_Desc\",\n    order=top10\n)\nplt.title(\"Top 10 Tipos de Atención Médica\")\nplt.xlabel(\"Número de facturas\")\nplt.ylabel(\"Concepto de Factura\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:35:08.290815Z","iopub.execute_input":"2025-04-25T04:35:08.291167Z","iopub.status.idle":"2025-04-25T04:35:13.147085Z","shell.execute_reply.started":"2025-04-25T04:35:08.291135Z","shell.execute_reply":"2025-04-25T04:35:13.146162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Asegurarse de que FECHA_ATENCION es datetime\ndf_salud['Mes'] = df_salud['FECHA_ATENCION'].dt.to_period('M')\n\n# Agrupar la demanda (Cantidad) por mes\ndemanda_por_mes = df_salud.groupby('Mes')['Cantidad'].sum().sort_index()\n\nplt.figure(figsize=(18,6))\ndemanda_por_mes.plot(marker='o')\nplt.title(\"Demanda Mensual Total\")\nplt.xlabel(\"Mes\")\nplt.ylabel(\"Cantidad\")\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:35:44.926452Z","iopub.execute_input":"2025-04-25T04:35:44.926801Z","iopub.status.idle":"2025-04-25T04:35:46.021647Z","shell.execute_reply.started":"2025-04-25T04:35:44.926770Z","shell.execute_reply":"2025-04-25T04:35:46.020661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Agrupar y sumar las cantidades por municipio\ndemanda_municipio = (\n    df_salud\n    .groupby(\"MUNICIPIO\", observed=True)[\"Cantidad\"]\n    .sum()\n    .reset_index()\n)\n\n# Obtener los 10 municipios con mayor demanda\ntop10 = demanda_municipio.nlargest(10, \"Cantidad\")\n\n# Ordenar los valores para el gráfico (opcional, dependiendo de la preferencia)\ntop10 = top10.sort_values(\"Cantidad\", ascending=True)\n\n# Crear el gráfico\nplt.figure(figsize=(12, 6))\nsns.barplot(\n    data=top10,\n    x=\"Cantidad\",\n    y=\"MUNICIPIO\",\n    order=top10[\"MUNICIPIO\"]  # Asegura el orden correcto\n)\nplt.title(\"Municipios con Mayor Demanda de Servicios\")\nplt.tight_layout()  # Mejora el espacio del gráfico\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:35:50.663934Z","iopub.execute_input":"2025-04-25T04:35:50.664277Z","iopub.status.idle":"2025-04-25T04:35:52.195712Z","shell.execute_reply.started":"2025-04-25T04:35:50.664251Z","shell.execute_reply":"2025-04-25T04:35:52.194656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Tendencias por tipo de servicio médico**","metadata":{}},{"cell_type":"code","source":"# Asegurarse de que FECHA_ATENCION es datetime\ndf_salud['Mes'] = df_salud['FECHA_ATENCION'].dt.to_period('M')\n\n# Agrupar por mes y tipo de atención\ntendencia_por_tipo = df_salud.groupby(['Mes', 'Concepto_Factura_Desc'])['Cantidad'].sum().reset_index()\n\n# Obtener los 10 tipos de atención más comunes para simplificar la visualización\ntop_tipos = df_salud['Concepto_Factura_Desc'].value_counts().nlargest(10).index\n\n# Filtrar solo los tipos top\ntendencia_por_tipo_top = tendencia_por_tipo[tendencia_por_tipo['Concepto_Factura_Desc'].isin(top_tipos)]\n\n# Convertir Mes a string para mejor visualización\ntendencia_por_tipo_top['Mes'] = tendencia_por_tipo_top['Mes'].astype(str)\n\n# Crear gráfico de líneas\nplt.figure(figsize=(16, 8))\nfor tipo in top_tipos:\n    data = tendencia_por_tipo_top[tendencia_por_tipo_top['Concepto_Factura_Desc'] == tipo]\n    plt.plot(data['Mes'], data['Cantidad'], marker='o', label=tipo)\n\nplt.title('Tendencia de Demanda por Tipo de Servicio Médico')\nplt.xlabel('Mes')\nplt.ylabel('Cantidad')\nplt.legend()\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:35:56.758692Z","iopub.execute_input":"2025-04-25T04:35:56.759116Z","iopub.status.idle":"2025-04-25T04:36:00.414911Z","shell.execute_reply.started":"2025-04-25T04:35:56.759083Z","shell.execute_reply":"2025-04-25T04:36:00.413940Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Análisis específico por municipio**","metadata":{}},{"cell_type":"code","source":"# Agrupar datos por municipio\ndatos_por_municipio = df_salud.groupby('MUNICIPIO').agg({\n    'Cantidad': 'sum',\n    'FECHA_ATENCION': 'count',\n    'Concepto_Factura_Desc': lambda x: x.nunique(),\n}).reset_index()\n\n# Renombrar columnas\ndatos_por_municipio.columns = ['Municipio', 'Total_Demanda', 'Num_Atenciones', 'Tipos_Servicio']\n\n# Calcular promedio de demanda por atención\ndatos_por_municipio['Demanda_Promedio'] = datos_por_municipio['Total_Demanda'] / datos_por_municipio['Num_Atenciones']\n\n# Visualizar estadísticas por municipio (todos los municipios)\nprint(\"Estadísticas por municipio:\")\ndisplay(datos_por_municipio.sort_values('Total_Demanda', ascending=False))\n\n# Analizar más a fondo los 10 municipios principales\ntop10_municipios = datos_por_municipio.nlargest(10, 'Total_Demanda')['Municipio'].tolist()\n\n# Para cada municipio top, analizar la tendencia mensual\nplt.figure(figsize=(15, 10))\n\nfor i, municipio in enumerate(top10_municipios):\n    # Filtrar datos del municipio\n    df_muni = df_salud[df_salud['MUNICIPIO'] == municipio]\n    \n    # Agrupar por mes\n    df_muni_mes = df_muni.groupby(df_muni['FECHA_ATENCION'].dt.to_period('M'))['Cantidad'].sum()\n    \n    # Crear subgráfico\n    plt.subplot(5, 2, i+1)\n    df_muni_mes.plot()\n    plt.title(f'Tendencia mensual: {municipio}')\n    plt.xlabel('Mes')\n    plt.ylabel('Cantidad')\n    plt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:36:28.022463Z","iopub.execute_input":"2025-04-25T04:36:28.022826Z","iopub.status.idle":"2025-04-25T04:36:42.439622Z","shell.execute_reply.started":"2025-04-25T04:36:28.022798Z","shell.execute_reply":"2025-04-25T04:36:42.438697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Patrones estacionales**","metadata":{}},{"cell_type":"code","source":"!pip install statsmodels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Crear variables para diferentes medidas temporales\ndf_salud['Año'] = df_salud['FECHA_ATENCION'].dt.year\ndf_salud['Mes'] = df_salud['FECHA_ATENCION'].dt.month\ndf_salud['DiaSemana'] = df_salud['FECHA_ATENCION'].dt.dayofweek  # 0=Lunes, 6=Domingo\ndf_salud['DiaMes'] = df_salud['FECHA_ATENCION'].dt.day\ndf_salud['Trimestre'] = df_salud['FECHA_ATENCION'].dt.quarter\n\n# 1. Análisis por mes del año\ndemanda_por_mes = df_salud.groupby('Mes')['Cantidad'].sum().reset_index()\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Mes', y='Cantidad', data=demanda_por_mes)\nplt.title('Demanda por Mes del Año')\nplt.xlabel('Mes')\nplt.ylabel('Cantidad')\nplt.xticks(range(12), ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic'])\nplt.show()\n\n# Análisis por día de la semana\ndemanda_por_dia = df_salud.groupby('DiaSemana')['Cantidad'].sum().reset_index()\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x='DiaSemana', y='Cantidad', data=demanda_por_dia)\nplt.title('Demanda por Día de la Semana')\nplt.xlabel('Día de la Semana')\nplt.ylabel('Cantidad')\nplt.xticks(range(7), ['Lun', 'Mar', 'Mié', 'Jue', 'Vie', 'Sáb', 'Dom'])\nplt.show()\n\n# Análisis por trimestre\ndemanda_por_trimestre = df_salud.groupby(['Año', 'Trimestre'])['Cantidad'].sum().reset_index()\n\nplt.figure(figsize=(12, 6))\nsns.lineplot(x='Trimestre', y='Cantidad', hue='Año', data=demanda_por_trimestre, marker='o')\nplt.title('Demanda Trimestral por Año')\nplt.xlabel('Trimestre')\nplt.ylabel('Cantidad')\nplt.grid(True)\nplt.show()\n\n\n# Análisis de estacionalidad \nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n# Preparar serie temporal para decomposición\nts_data = df_salud.groupby(df_salud['FECHA_ATENCION'].dt.to_period('M'))['Cantidad'].sum()\nts_data.index = pd.to_datetime(ts_data.index.astype(str))\n\n# Realizar descomposición estacional (si hay suficientes datos)\nif len(ts_data) >= 24:  # Necesitamos al menos 2 años de datos\n    decomposition = seasonal_decompose(ts_data, model='additive', period=12)\n    \n    # Graficar la descomposición\n    plt.figure(figsize=(12, 10))\n    plt.subplot(411)\n    plt.plot(ts_data, label='Original')\n    plt.legend(loc='best')\n    plt.title('Descomposición Estacional')\n    \n    plt.subplot(412)\n    plt.plot(decomposition.trend, label='Tendencia')\n    plt.legend(loc='best')\n    \n    plt.subplot(413)\n    plt.plot(decomposition.seasonal, label='Estacionalidad')\n    plt.legend(loc='best')\n    \n    plt.subplot(414)\n    plt.plot(decomposition.resid, label='Residuos')\n    plt.legend(loc='best')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:36:47.798223Z","iopub.execute_input":"2025-04-25T04:36:47.798527Z","iopub.status.idle":"2025-04-25T04:36:54.121155Z","shell.execute_reply.started":"2025-04-25T04:36:47.798505Z","shell.execute_reply":"2025-04-25T04:36:54.120201Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Detección de valores atípicos, datos faltantes y errores**","metadata":{}},{"cell_type":"code","source":"# Análisis de valores faltantes\nprint(\"Total de valores faltantes por columna:\")\nprint(df_salud.isnull().sum())\n\n# Visualización de valores faltantes\nplt.figure(figsize=(12, 6))\nsns.heatmap(df_salud.isnull(), cbar=False, yticklabels=False, cmap='viridis')\nplt.title('Mapa de Valores Faltantes')\nplt.show()\n\n# Detección de valores atípicos en la variable \"Cantidad\"\nplt.figure(figsize=(10, 6))\nsns.boxplot(y=df_salud['Cantidad'])\nplt.title('Distribución de la Variable Cantidad')\nplt.ylabel('Cantidad')\nplt.show()\n\n# Cálculo de percentiles para identificar outliers\nQ1 = df_salud['Cantidad'].quantile(0.25)\nQ3 = df_salud['Cantidad'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\nprint(f\"Valores atípicos - Límite inferior: {lower_bound}, Límite superior: {upper_bound}\")\nprint(f\"Número de outliers: {df_salud[(df_salud['Cantidad'] < lower_bound) | (df_salud['Cantidad'] > upper_bound)].shape[0]}\")\n\n# Análisis de valores inconsistentes\n# Verificar si hay cantidades negativas o cero (que podrían ser erróneas)\nprint(f\"Registros con cantidad negativa: {df_salud[df_salud['Cantidad'] < 0].shape[0]}\")\nprint(f\"Registros con cantidad cero: {df_salud[df_salud['Cantidad'] == 0].shape[0]}\")\n\n# Verificación de fechas\nmin_date = df_salud['FECHA_ATENCION'].min()\nmax_date = df_salud['FECHA_ATENCION'].max()\nprint(f\"Rango de fechas: {min_date} a {max_date}\")\n\n# Comprobar si hay fechas futuras (posteriores a la fecha actual)\nfuture_dates = df_salud[df_salud['FECHA_ATENCION'] > pd.Timestamp.now()]\nprint(f\"Registros con fechas futuras: {future_dates.shape[0]}\")\n\n# Verificar duplicados exactos\nduplicados = df_salud.duplicated()\nprint(f\"Número de registros duplicados: {duplicados.sum()}\")\n\n# Comprobar problemas potenciales en los valores categóricos\nfor col in ['Concepto_Factura_Desc', 'MUNICIPIO']:\n    n_values = df_salud[col].nunique()\n    print(f\"Columna {col}: {n_values} valores únicos\")\n    \n    # Si hay muchos valores únicos, puede haber inconsistencias\n    if n_values > 100:  # Umbral arbitrario\n        print(\"  ⚠️ Esta columna tiene muchos valores únicos, posible inconsistencia en nomenclatura\")\n        \n        # Mostrar los valores más y menos frecuentes\n        print(\"  Valores más comunes:\")\n        print(df_salud[col].value_counts().head())\n        print(\"  Valores menos comunes:\")\n        print(df_salud[col].value_counts().tail())\n\n# Análisis de la capacidad máxima del prestador vs. demanda real\nif 'Geogra_Municipio_Id' in df_salud.columns and 'Geogra_Municipio_Id' in df_prestadores.columns:\n    # Agrupar demanda por municipio\n    demanda_municipio = df_salud.groupby('Geogra_Municipio_Id')['Cantidad'].sum().reset_index()\n    \n    # Combinar con información de capacidad\n    analisis_capacidad = demanda_municipio.merge(df_prestadores, on='Geogra_Municipio_Id', how='inner')\n    analisis_capacidad['Porcentaje_Uso'] = (analisis_capacidad['Cantidad'] / analisis_capacidad['max_cantidad']) * 100\n    \n    # Identificar posibles problemas\n    print(\"Municipios con posible sobrecarga (uso > 90%):\")\n    display(analisis_capacidad[analisis_capacidad['Porcentaje_Uso'] > 90])\n    \n    print(\"Municipios con baja utilización (uso < 20%):\")\n    display(analisis_capacidad[analisis_capacidad['Porcentaje_Uso'] < 20])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:37:03.196236Z","iopub.execute_input":"2025-04-25T04:37:03.196872Z","execution_failed":"2025-04-25T04:38:03.734Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Análisis de series temporales específico**","metadata":{}},{"cell_type":"code","source":"import matplotlib.dates as mdates\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf\nimport statsmodels.api as sm\n\n# Preparar serie temporal diaria\nts_diaria = df_salud.groupby(df_salud['FECHA_ATENCION'].dt.date)['Cantidad'].sum()\nts_diaria.index = pd.to_datetime(ts_diaria.index)\n\n# Visualizar la serie temporal completa\nplt.figure(figsize=(15, 7))\nplt.plot(ts_diaria)\nplt.title('Serie Temporal Diaria de Demanda')\nplt.xlabel('Fecha')\nplt.ylabel('Cantidad')\nplt.grid(True)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Analizar la estacionariedad de la serie\nresult = adfuller(ts_diaria.dropna())\nprint('Prueba de Dickey-Fuller Aumentada:')\nprint(f'Estadística de prueba: {result[0]}')\nprint(f'Valor p: {result[1]}')\nprint(f'Valores críticos: {result[4]}')\nif result[1] <= 0.05:\n    print(\"La serie es estacionaria (rechazamos H0)\")\nelse:\n    print(\"La serie no es estacionaria (no rechazamos H0)\")\n\n# Analizar autocorrelación\nplt.figure(figsize=(12, 10))\n\n# ACF\nplt.subplot(211)\nsm.graphics.tsa.plot_acf(ts_diaria.dropna(), lags=40, ax=plt.gca())\nplt.title('Función de Autocorrelación (ACF)')\n\n# PACF\nplt.subplot(212)\nsm.graphics.tsa.plot_pacf(ts_diaria.dropna(), lags=40, ax=plt.gca())\nplt.title('Función de Autocorrelación Parcial (PACF)')\n\nplt.tight_layout()\nplt.show()\n\n# Descomposición de la serie temporal (tendencia, estacionalidad, residuos)\n# Usar la serie semanal para reducir el ruido\nts_semanal = df_salud.groupby(pd.Grouper(key='FECHA_ATENCION', freq='W'))['Cantidad'].sum()\n\n# Realizar descomposición\ndescomposicion = sm.tsa.seasonal_decompose(ts_semanal, model='additive', period=52)\n\n# Graficar\nfig = descomposicion.plot()\nfig.set_size_inches(15, 12)\nplt.tight_layout()\nplt.show()\n\n# Análisis de venta móvil para detectar tendencias a largo plazo\nventanas = [7, 30, 90, 180]\nplt.figure(figsize=(15, 8))\n\nplt.plot(ts_diaria, alpha=0.5, label='Original')\n\nfor ventana in ventanas:\n    ts_ma = ts_diaria.rolling(window=ventana).mean()\n    plt.plot(ts_ma, label=f'Media Móvil ({ventana} días)')\n\nplt.title('Análisis de Tendencia con Medias Móviles')\nplt.xlabel('Fecha')\nplt.ylabel('Cantidad')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **PIPELINE**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nfrom statsmodels.tsa.arima.model import ARIMA\nimport xgboost as xgb\nimport holidays\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import TimeSeriesSplit, ParameterGrid\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# ------------------------- Configuración -------------------------------\nGPUS = tf.config.list_physical_devices('GPU')\nif GPUS:\n    for g in GPUS:\n        tf.config.experimental.set_memory_growth(g, True)\n    print(f\"GPUs detectadas: {len(GPUS)}\")\nelse:\n    print(\"Usando CPU\")\n\nXGB_PARAMS = {'tree_method':'gpu_hist','predictor':'gpu_predictor','verbosity':0}\nWINDOW = 30\nTOP_N = 10\nTOP_M = 2\nCV_SPLITS = 5\nHORIZON = 365  # días a predecir\n\n# ------------------------- Métricas extendidas ---------------------------\ndef smape(y_true, y_pred):\n    denom = (np.abs(y_true) + np.abs(y_pred)) / 2\n    mask = denom != 0\n    return 100 * np.mean(np.abs(y_true[mask] - y_pred[mask]) / denom[mask])\n\ndef mase(y_true, y_pred, y_insample, season=1):\n    mae_model = mean_absolute_error(y_true, y_pred)\n    diff = np.abs(y_insample[season:] - y_insample[:-season])\n    mae_naive = diff.mean()\n    return mae_model / mae_naive if mae_naive != 0 else np.nan\n\n# ------------------------- Data Prep ---------------------------------------\ndef load_data(path):\n    df = pd.read_csv(path, sep='|', usecols=['FECHA_ATENCION','Concepto_Factura_Desc','Cantidad','MUNICIPIO'],\n                     parse_dates=['FECHA_ATENCION'])\n    df.drop_duplicates(inplace=True)\n    df = df[df['Cantidad'].notna()]\n    df['MUNICIPIO'] = df['MUNICIPIO'].str.split('-').str[0].str.strip()\n    return df\n\n# Exógenas\ndef make_exog(idx):\n    cal = holidays.Colombia()\n    df_ex = pd.DataFrame(index=idx)\n    df_ex['is_weekend'] = (idx.dayofweek >= 5).astype(int)\n    df_ex['is_holiday'] = idx.to_series().apply(lambda d: 1 if d in cal else 0)\n    df_ex['covid'] = idx.to_series().apply(lambda d: 1 if (d.year==2020 and d.month>=3) or d.year==2021 else 0)\n    return df_ex\n\n# Serie diaria univariante\ndef get_ts(df, muni, serv):\n    ts = df[(df['MUNICIPIO']==muni)&(df['Concepto_Factura_Desc']==serv)]\n    ts = ts.set_index('FECHA_ATENCION')['Cantidad']\n    ts = ts.resample('D').sum().asfreq('D').fillna(0)\n    return ts\n\n# Features: lags + exógenas\ndef make_features(ts):\n    ex = make_exog(ts.index)\n    df_feat = ex.copy(); df_feat['y'] = ts\n    for L in [7, 30]: df_feat[f'lag_{L}'] = df_feat['y'].shift(L)\n    df_feat['roll7'] = df_feat['y'].rolling(7).mean().shift(1)\n    df_feat.dropna(inplace=True)\n    return df_feat.drop('y',axis=1), df_feat['y']\n\n# Secuencias para DL\ndef make_seq(vals, w):\n    X, y = [], []\n    for i in range(len(vals) - w): X.append(vals[i:i+w]); y.append(vals[i+w])\n    return np.array(X), np.array(y)\n\n# ------------------------- Train/Evaluate CV -------------------------------\ndef train_evaluate(ts, model_type, params):\n    tscv = TimeSeriesSplit(n_splits=CV_SPLITS)\n    scores = []\n    y_insample = ts.values\n    for tr, te in tscv.split(ts):\n        t_tr, t_te = ts.iloc[tr], ts.iloc[te]\n        if len(t_tr) < WINDOW + 1 or len(t_te) == 0: continue\n        # Combined\n        if model_type == 'Combined':\n            ar = ARIMA(t_tr, order=(1,1,1)).fit()\n            resid = (t_tr - ar.fittedvalues).dropna()\n            Xr, yr = make_features(resid)\n            xbm = xgb.XGBRegressor(**params).fit(Xr, yr)\n            fc_ar = ar.forecast(steps=len(t_te))\n            hist = pd.concat([resid, pd.Series(fc_ar, index=t_te.index)])\n            Xf, _ = make_features(hist)\n            Xf = Xf.loc[t_te.index]\n            fc_xgb = xbm.predict(Xf)\n            y_pred = fc_ar.values + fc_xgb; y_true = t_te.values\n        # LSTM\n        elif model_type == 'LSTM':\n            Xtr, Ytr = make_seq(t_tr.values, WINDOW)\n            Xte, _ = make_seq(np.concatenate([t_tr.values[-WINDOW:], t_te.values]), WINDOW)\n            model = models.Sequential([\n                layers.Input((WINDOW,1)), layers.LSTM(params['units']), layers.Dropout(0.2), layers.Dense(1)\n            ])\n            model.compile('adam','mse')\n            es = callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n            model.fit(Xtr.reshape(-1,WINDOW,1), Ytr,\n                      epochs=params['epochs'], batch_size=32, validation_split=0.1,\n                      verbose=0, callbacks=[es])\n            y_pred = model.predict(Xte.reshape(-1,WINDOW,1), verbose=0).flatten()[-len(t_te):]; y_true = t_te.values\n        # NBeats\n        else:\n            Xtr, Ytr = make_seq(t_tr.values, WINDOW)\n            Xte, _ = make_seq(np.concatenate([t_tr.values[-WINDOW:], t_te.values]), WINDOW)\n            class Block(layers.Layer):\n                def __init__(self):\n                    super().__init__()\n                    self.hidden = [layers.Dense(params['units'], activation='relu') for _ in range(4)]\n                    self.backcast = layers.Dense(WINDOW)\n                    self.forecast = layers.Dense(1)\n                def call(self, x):\n                    h = x\n                    for lyr in self.hidden: h = lyr(h)\n                    return self.backcast(h), self.forecast(h)\n            inp = layers.Input(shape=(WINDOW,)); res = inp; fc = 0\n            for _ in range(params['stacks']): b, f = Block()(res); res -= b; fc += f\n            nb = models.Model(inp, fc); nb.compile('adam','mse')\n            es = callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n            nb.fit(Xtr, Ytr, epochs=params['epochs'], batch_size=32, validation_split=0.1,\n                   verbose=0, callbacks=[es])\n            y_pred = nb.predict(Xte, verbose=0).flatten()[-len(t_te):]; y_true = t_te.values\n        # Métricas\n        rmse = mean_squared_error(y_true, y_pred, squared=False)\n        mae  = mean_absolute_error(y_true, y_pred)\n        sm   = smape(y_true, y_pred)\n        mz   = mase(y_true, y_pred, y_insample)\n        scores.append({'RMSE':rmse,'MAE':mae,'SMAPE':sm,'MASE':mz})\n    return pd.DataFrame(scores).mean() if scores else pd.Series({'RMSE':np.nan,'MAE':np.nan,'SMAPE':np.nan,'MASE':np.nan})\n\n# Nested CV tuning NBeats\ndef nested_cv(ts, grid):\n    outer = TimeSeriesSplit(n_splits=3)\n    best_p, best_s = None, np.inf\n    for tr, _ in outer.split(ts):\n        t_tr = ts.iloc[tr]\n        for p in ParameterGrid(grid):\n            r = train_evaluate(t_tr, 'NBeats', p)['RMSE']\n            if r < best_s: best_s, best_p = r, p\n    return best_p, best_s\n\n# ------------------------- Visualización -------------------------------\ndef plot_model_metrics(summary):\n    df = pd.DataFrame(summary).set_index('model')\n    df[['RMSE','MAE','SMAPE','MASE']].plot(kind='bar')\n    plt.title('Comparación de métricas por modelo')\n    plt.tight_layout()\n    plt.show()\n\n# Retrain completo y forecast iterativo para un modelo\ndef retrain_and_forecast(ts, model_type, params, horizon=HORIZON):\n    dates = pd.date_range(ts.index[-1] + pd.Timedelta(days=1), periods=horizon, freq='D')\n    # Combined\n    if model_type == 'Combined':\n        ar = ARIMA(ts, order=(1,1,1)).fit()\n        resid = (ts - ar.fittedvalues).dropna()\n        Xr, yr = make_features(resid)\n        xbm = xgb.XGBRegressor(**params).fit(Xr, yr)\n        fc_ar = ar.forecast(steps=horizon)\n        series_all = pd.concat([ts, pd.Series(fc_ar.values, index=dates)])\n        Xf, _ = make_features(series_all)\n        Xf_future = Xf.loc[dates]\n        fc_xgb = xbm.predict(Xf_future)\n        return pd.Series(fc_ar.values + fc_xgb, index=dates)\n    # LSTM\n    if model_type == 'LSTM':\n        X, Y = make_seq(ts.values, WINDOW)\n        model = models.Sequential([\n            layers.Input((WINDOW,1)), layers.LSTM(params['units']), layers.Dropout(0.2), layers.Dense(1)\n        ])\n        model.compile('adam','mse')\n        es = callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n        model.fit(X.reshape(-1,WINDOW,1), Y, epochs=params['epochs'], batch_size=32,\n                  validation_split=0.1, verbose=0, callbacks=[es])\n        hist = ts.values.tolist(); preds = []\n        for _ in range(horizon):\n            x = np.array(hist[-WINDOW:]).reshape(1,WINDOW,1)\n            y_pred = model.predict(x, verbose=0).flatten()[0]\n            preds.append(y_pred); hist.append(y_pred)\n        return pd.Series(preds, index=dates)\n    # NBeats\n    X, Y = make_seq(ts.values, WINDOW)\n    class Block(layers.Layer):\n        def __init__(self):\n            super().__init__(); self.hidden=[layers.Dense(params['units'],activation='relu') for _ in range(4)];\n            self.backcast=layers.Dense(WINDOW); self.forecast=layers.Dense(1)\n        def call(self,x):\n            h=x\n            for lyr in self.hidden: h=lyr(h)\n            return self.backcast(h), self.forecast(h)\n    inp=layers.Input(shape=(WINDOW,)); res=inp; fc=0\n    for _ in range(params['stacks']): b,f=Block()(res); res-=b; fc+=f\n    nb = models.Model(inp, fc); nb.compile('adam','mse')\n    es=callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n    nb.fit(X, Y, epochs=params['epochs'], batch_size=32, validation_split=0.1,\n           verbose=0, callbacks=[es])\n    hist = ts.values.tolist(); preds = []\n    for _ in range(horizon):\n        x = np.array(hist[-WINDOW:]).reshape(1,WINDOW)\n        y_pred = nb.predict(x, verbose=0).flatten()[0]\n        preds.append(y_pred); hist.append(y_pred)\n    return pd.Series(preds, index=dates)\n\n# ------------------------- Ejecución Principal ----------------------------\nif __name__=='__main__':\n    df = load_data('/kaggle/input/data-sura/1.Informacion Salud 2019-2024-001.txt')\n    top_munis = df.groupby('MUNICIPIO')['Cantidad'].sum().nlargest(TOP_N).index\n    top_munis = df.groupby('MUNICIPIO')['Cantidad'].sum().nlargest(TOP_N).index\n    combos = [(m, s) for m in top_munis for s in df[df['MUNICIPIO']==m]\n              .groupby('Concepto_Factura_Desc')['Cantidad'].sum().nlargest(TOP_M).index]\n    print(f\"Procesando {len(combos)} combos\")\n\n    # Evaluación de modelos y selección del mejor\n    summary = []\n    best_p = None\n    for model_type in ['Combined','LSTM','NBeats']:\n        params = XGB_PARAMS if model_type=='Combined' else {'epochs':10,'units':64} if model_type=='LSTM' else nested_cv(get_ts(df,*combos[0]),{'epochs':[10,20],'stacks':[2,3],'units':[128,256]})[0]\n        metrics_list = [train_evaluate(get_ts(df,m,s), model_type, params)\n                        for m, s in combos if len(get_ts(df,m,s)) > WINDOW*2]\n        avg = pd.DataFrame(metrics_list).mean().to_dict(); avg['model'] = model_type\n        summary.append(avg)\n        if avg['RMSE'] == min([x['RMSE'] for x in summary]):\n            best_model = model_type; best_p = params\n\n    print(f\"Mejor modelo: {best_model}\")\n    plot_model_metrics(summary)\n\n    # Pronósticos para los primeros 5 combos (un combo por municipio)\n    for muni, serv in combos:\n        ts = get_ts(df, muni, serv)\n        fc = retrain_and_forecast(ts, best_model, best_p, horizon=HORIZON)\n        plt.figure()\n        plt.plot(ts[-365:], label='Histórico')\n        plt.plot(fc, label='Forecast')\n        plt.title(f'Pronóstico {best_model} para {muni} - {serv}')\n        plt.legend()\n        plt.tight_layout()\n        plt.show()\n\n    print('Pipeline completado.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T06:41:42.206221Z","iopub.execute_input":"2025-04-25T06:41:42.206518Z","iopub.status.idle":"2025-04-25T07:25:06.430215Z","shell.execute_reply.started":"2025-04-25T06:41:42.206496Z","shell.execute_reply":"2025-04-25T07:25:06.429306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(pd.DataFrame(summary))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T07:25:34.514830Z","iopub.execute_input":"2025-04-25T07:25:34.515188Z","iopub.status.idle":"2025-04-25T07:25:34.533459Z","shell.execute_reply.started":"2025-04-25T07:25:34.515161Z","shell.execute_reply":"2025-04-25T07:25:34.532530Z"}},"outputs":[],"execution_count":null}]}